{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "e4e_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhluu99/Text-Driven-Face-Image-Manipulation/blob/master/e4e_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnfPWnXsyIlI",
        "outputId": "ea5b9011-1fec-4d34-eb55-15dc3b3b998f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmis8SOT0LXR",
        "cellView": "form",
        "outputId": "b777b3fe-8d68-407c-fb54-c5be443c5d57"
      },
      "source": [
        "#@title Khai báo và khởi tạo một số thư mục cần thiết\n",
        "import os\n",
        "ThuMucLamViec = \"/content/drive/MyDrive/LuuGiaMinh_GAN/e4e\" #@param {type:\"string\"}\n",
        "assert os.path.exists(ThuMucLamViec),\"Không tìm thấy ThuMucLamViec\"\n",
        "assert os.path.isdir(ThuMucLamViec),\"SaveDir phải là thư mục Folder\"\n",
        "import os\n",
        "ExpDir = '/content/drive/MyDrive/T2' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "os.chdir(ThuMucLamViec)\n",
        "\n",
        "CodeDir = 'encoder4editing'\n",
        "if not os.path.exists(CodeDir):\n",
        "  !git clone https://github.com/omertov/encoder4editing.git\n",
        "\n",
        "  # Tải một số file .pt theo yêu cầu của tác giả\n",
        "  model_dir = CodeDir + '/pretrained_models'\n",
        "  !mkdir $model_dir\n",
        "  os.chdir(model_dir)\n",
        "  !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "  !bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "  os.chdir('..')\n",
        "  model_path = 'model_ir_se50.pth'\n",
        "  print(os.path.abspath(model_path))\n",
        "  !cp $model_path $model_dir\n",
        "  model_path = 'stylegan2-ffhq-config-f.pt'\n",
        "  !cp $model_path $model_dir\n",
        "  model_path = 'moco_v2_800ep_pretrain.pt'\n",
        "  !cp $model_path $model_dir\n",
        "\n",
        "os.chdir(CodeDir)\n",
        "!pip install ninja\n",
        "os.environ['PYTHONPATH'] = os.path.join(ThuMucLamViec,CodeDir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTPkgtby4ehh"
      },
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "si6vQFmT0-Bz",
        "outputId": "4cab806a-91c0-406c-b9fd-79394041629d"
      },
      "source": [
        "if os.path.exists(ExpDir):\n",
        "  print('Checkpoint đã tồn tại')\n",
        "  i = input('Y để huấn luyện lại, N để kết thúc: ')\n",
        "  if i == 'Y' or i == 'y':\n",
        "    !rm -r $ExpDir\n",
        "  else:\n",
        "    raise Exception('Đã dừng, sẽ không huấn luyện')\n",
        "\n",
        "!python scripts/train.py \\\n",
        "--dataset_type my_data_encode2 \\\n",
        "--exp_dir $ExpDir \\\n",
        "--id_lambda 0.1 \\\n",
        "--keep_optimizer \\\n",
        "--start_from_latent_avg \\\n",
        "--use_w_pool \\\n",
        "--w_discriminator_lambda 0.1 \\\n",
        "--progressive_start 20000 \\\n",
        "--val_interval 2000 \\\n",
        "--save_interval 2000 \\\n",
        "--max_steps 200000 \\\n",
        "--stylegan_size 1024 \\\n",
        "--workers 8 \\\n",
        "--batch_size 8 \\\n",
        "--test_batch_size 4 \\\n",
        "--test_workers 4 \\\n",
        "--save_training_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint đã tồn tại\n",
            "Y để huấn luyện lại, N để kết thúc: n\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-445ffe8cb30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -r $ExpDir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Đã dừng, sẽ không huấn luyện'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python scripts/train.py --dataset_type my_data_encode2 --exp_dir $ExpDir --id_lambda 0.1 --keep_optimizer --start_from_latent_avg --use_w_pool --w_discriminator_lambda 0.1 --progressive_start 20000 --val_interval 2000 --save_interval 2000 --max_steps 200000 --stylegan_size 1024 --workers 8 --batch_size 8 --test_batch_size 4 --test_workers 4 --save_training_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Đã dừng, sẽ không huấn luyện"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4mHr909-Pgz",
        "outputId": "bd6eb891-37ad-4a41-d9b5-df192958d07e"
      },
      "source": [
        "# !python scripts/train.py \\\n",
        "# --dataset_type my_data_encode \\\n",
        "# --exp_dir $ExpDir \\\n",
        "# --start_from_latent_avg \\\n",
        "# --use_w_pool \\\n",
        "# --w_discriminator_lambda 0.1 \\\n",
        "# --progressive_start 20000 \\\n",
        "# --id_lambda 0.5 \\\n",
        "# --val_interval 1000 \\\n",
        "# --save_interval 1000 \\\n",
        "# --max_steps 200000 \\\n",
        "# --stylegan_size 512 \\\n",
        "# --workers 8 \\\n",
        "# --batch_size 8 \\\n",
        "# --test_batch_size 4 \\\n",
        "# --test_workers 4 \\\n",
        "# --save_training_data \\\n",
        "# --resume_training_from_ckpt ../Test/T1/checkpoints/iteration_10000.pt \\\n",
        "# --keep_optimizer\n",
        "\n",
        "!python scripts/train.py \\\n",
        "--dataset_type my_data_encode2 \\\n",
        "--exp_dir $ExpDir \\\n",
        "--id_lambda 0.1 \\\n",
        "--keep_optimizer \\\n",
        "--start_from_latent_avg \\\n",
        "--use_w_pool \\\n",
        "--w_discriminator_lambda 0.1 \\\n",
        "--progressive_start 20000 \\\n",
        "--val_interval 2000 \\\n",
        "--save_interval 2000 \\\n",
        "--max_steps 200000 \\\n",
        "--stylegan_size 1024 \\\n",
        "--workers 8 \\\n",
        "--batch_size 8 \\\n",
        "--test_batch_size 4 \\\n",
        "--test_workers 4 \\\n",
        "--save_training_data \\\n",
        "--resume_training_from_ckpt ../Test/T2/checkpoints/iteration_30000.pt "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 8,\n",
            " 'board_interval': 50,\n",
            " 'checkpoint_path': None,\n",
            " 'd_reg_every': 16,\n",
            " 'dataset_type': 'my_data_encode2',\n",
            " 'delta_norm': 2,\n",
            " 'delta_norm_lambda': 0.0002,\n",
            " 'device': 'cuda:0',\n",
            " 'encoder_type': 'Encoder4Editing',\n",
            " 'exp_dir': '../Test/T2',\n",
            " 'id_lambda': 0.1,\n",
            " 'image_interval': 100,\n",
            " 'keep_optimizer': True,\n",
            " 'l2_lambda': 1.0,\n",
            " 'learning_rate': 0.0001,\n",
            " 'lpips_lambda': 0.8,\n",
            " 'lpips_type': 'alex',\n",
            " 'max_steps': 200000,\n",
            " 'optim_name': 'ranger',\n",
            " 'progressive_start': 20000,\n",
            " 'progressive_step_every': 2000,\n",
            " 'progressive_steps': [0,\n",
            "                       20000,\n",
            "                       22000,\n",
            "                       24000,\n",
            "                       26000,\n",
            "                       28000,\n",
            "                       30000,\n",
            "                       32000,\n",
            "                       34000,\n",
            "                       36000,\n",
            "                       38000,\n",
            "                       40000,\n",
            "                       42000,\n",
            "                       44000,\n",
            "                       46000,\n",
            "                       48000,\n",
            "                       50000,\n",
            "                       52000],\n",
            " 'r1': 10,\n",
            " 'resume_training_from_ckpt': '../Test/T2/checkpoints/iteration_30000.pt',\n",
            " 'save_interval': 2000,\n",
            " 'save_training_data': True,\n",
            " 'start_from_latent_avg': True,\n",
            " 'stylegan_size': 1024,\n",
            " 'stylegan_weights': 'pretrained_models/stylegan2-ffhq-config-f.pt',\n",
            " 'sub_exp_dir': None,\n",
            " 'test_batch_size': 4,\n",
            " 'test_workers': 4,\n",
            " 'train_decoder': False,\n",
            " 'update_param_list': None,\n",
            " 'use_w_pool': True,\n",
            " 'val_interval': 2000,\n",
            " 'w_discriminator_lambda': 0.1,\n",
            " 'w_discriminator_lr': 2e-05,\n",
            " 'w_pool_size': 50,\n",
            " 'workers': 8}\n",
            "Loading encoders weights from irse50!\n",
            "Loading decoder weights from pretrained!\n",
            "Loading MOCO model from path: pretrained_models/moco_v2_800ep_pretrain.pt\n",
            "Loading dataset for my_data_encode2\n",
            "Number of training samples: 9033\n",
            "Number of test samples: 1000\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Loading previous training data...\n",
            "Changed progressive stage to:  ProgressiveStage.WTraining\n",
            "Changed progressive stage to:  ProgressiveStage.Delta1Training\n",
            "Changed progressive stage to:  ProgressiveStage.Delta2Training\n",
            "Changed progressive stage to:  ProgressiveStage.Delta3Training\n",
            "Changed progressive stage to:  ProgressiveStage.Delta4Training\n",
            "Changed progressive stage to:  ProgressiveStage.Delta5Training\n",
            "Changed progressive stage to:  ProgressiveStage.Delta6Training\n",
            "Resuming training from step 30001\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/content/drive/MyDrive/LuuGiaMinh_GAN/e4e/encoder4editing/training/ranger.py:123: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/train.py\", line 87, in <module>\n",
            "    main()\n",
            "  File \"scripts/train.py\", line 28, in main\n",
            "    coach.train()\n",
            "  File \"/content/drive/MyDrive/LuuGiaMinh_GAN/e4e/encoder4editing/training/coach.py\", line 118, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\", line 199, in apply\n",
            "    return user_fn(self, *args)\n",
            "  File \"/content/drive/MyDrive/LuuGiaMinh_GAN/e4e/encoder4editing/models/stylegan2/op/fused_act.py\", line 66, in backward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzQJSl00dpql",
        "outputId": "84d5f010-1c29-4b9e-ab2f-ddbb21f85591"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "! pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.4 MB/s eta 0:03:49tcmalloc: large alloc 1147494400 bytes == 0x557474d0c000 @  0x7fc2cac70615 0x55743af5e4cc 0x55743b03e47a 0x55743af612ed 0x55743b052e1d 0x55743afd4e99 0x55743afcf9ee 0x55743af62bda 0x55743afd4d00 0x55743afcf9ee 0x55743af62bda 0x55743afd1737 0x55743b053c66 0x55743afd0daf 0x55743b053c66 0x55743afd0daf 0x55743b053c66 0x55743afd0daf 0x55743af63039 0x55743afa6409 0x55743af61c52 0x55743afd4c25 0x55743afcf9ee 0x55743af62bda 0x55743afd1737 0x55743afcf9ee 0x55743af62bda 0x55743afd0915 0x55743af62afa 0x55743afd0c0d 0x55743afcf9ee\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.2 MB/s eta 0:01:23tcmalloc: large alloc 1434370048 bytes == 0x5574b9362000 @  0x7fc2cac70615 0x55743af5e4cc 0x55743b03e47a 0x55743af612ed 0x55743b052e1d 0x55743afd4e99 0x55743afcf9ee 0x55743af62bda 0x55743afd4d00 0x55743afcf9ee 0x55743af62bda 0x55743afd1737 0x55743b053c66 0x55743afd0daf 0x55743b053c66 0x55743afd0daf 0x55743b053c66 0x55743afd0daf 0x55743af63039 0x55743afa6409 0x55743af61c52 0x55743afd4c25 0x55743afcf9ee 0x55743af62bda 0x55743afd1737 0x55743afcf9ee 0x55743af62bda 0x55743afd0915 0x55743af62afa 0x55743afd0c0d 0x55743afcf9ee\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 43.6 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55750eb4e000 @  0x7fc2cac70615 0x55743af5e4cc 0x55743b03e47a 0x55743af612ed 0x55743b052e1d 0x55743afd4e99 0x55743afcf9ee 0x55743af62bda 0x55743afd0c0d 0x55743afcf9ee 0x55743af62bda 0x55743afd0c0d 0x55743afcf9ee 0x55743af62bda 0x55743afd0c0d 0x55743afcf9ee 0x55743af62bda 0x55743afd0c0d 0x55743afcf9ee 0x55743af62bda 0x55743afd0c0d 0x55743af62afa 0x55743afd0c0d 0x55743afcf9ee 0x55743af62bda 0x55743afd1737 0x55743afcf9ee 0x55743af62bda 0x55743afd1737 0x55743afcf9ee 0x55743af63271\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 151 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmHNQN1dzysW",
        "outputId": "f64266d5-f6d1-4735-df05-3d1bbd82c681"
      },
      "source": [
        "!python scripts/inference.py \\\n",
        "--images_dir='../anh_tu_them' \\\n",
        "--save_dir=../Test/T1_inferrence \\\n",
        "--align \\\n",
        "--n_sample=1 \\\n",
        "../Test/T1/checkpoints/iteration_133000.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading e4e over the pSp framework from checkpoint: ../Test/T1/checkpoints/iteration_133000.pt\n",
            "images path: ../anh_tu_them\n",
            "dataset length: 22\n",
            "Aligned image has shape: (256, 256)\n",
            "Aligned image has shape: (256, 256)\n",
            "Aligned image has shape: (256, 256)\n",
            "Aligned image has shape: (256, 256)\n",
            "Aligned image has shape: (256, 256)\n",
            "Aligned image has shape: (256, 256)\n",
            "Saving inversion images\n"
          ]
        }
      ]
    }
  ]
}